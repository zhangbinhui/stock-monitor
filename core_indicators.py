#!/usr/bin/env python3
"""
åŠ¨æ€æ ¸å¿ƒæŒ‡æ ‡å¼•æ“

æ ¹æ®æŒä»“çš„æ—å¥‡åˆ†ç±»+è¡Œä¸š+å½“å‰çŠ¶æ€ï¼Œè‡ªåŠ¨æ¨æ–­éœ€è¦è·Ÿè¸ªçš„æŒ‡æ ‡å¹¶æŠ“å–æœ€æ–°æ•°æ®ã€‚
- æ–°è‚¡å…¥æ±  â†’ è‡ªåŠ¨ç”ŸæˆæŒ‡æ ‡
- æ•°æ®æ»šåŠ¨ â†’ 2æœˆäº§é”€å‡ºäº†è‡ªåŠ¨ç­‰3æœˆ
- å‚¬åŒ–å‰‚åˆ°æœŸ â†’ å¹´æŠ¥å‡ºäº†åˆ‡åˆ°Q1æŠ¥
"""

import json
import os
import logging
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional

log = logging.getLogger("core_indicators")

CACHE_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data", "indicator_cache.json")

# ============================================================
# ç¼“å­˜
# ============================================================

def _load_cache() -> Dict:
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {}


def _save_cache(cache: Dict):
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)


def _get_cached(key: str, max_age_hours: int = 12) -> Optional[Dict]:
    """è·å–ç¼“å­˜ï¼Œè¶…è¿‡ max_age_hours è¿‡æœŸ"""
    cache = _load_cache()
    item = cache.get(key)
    if item:
        ts = item.get('timestamp', 0)
        age = (datetime.now().timestamp() - ts) / 3600
        if age < max_age_hours:
            return item.get('data')
    return None


def _set_cached(key: str, data):
    cache = _load_cache()
    cache[key] = {'data': data, 'timestamp': datetime.now().timestamp()}
    _save_cache(cache)


# ============================================================
# æ•°æ®æŠ“å–å‡½æ•°
# ============================================================

def fetch_southbound_flow() -> Optional[Dict]:
    """å—å‘èµ„é‡‘å‡€æµå…¥"""
    cached = _get_cached('southbound_flow')
    if cached:
        return cached
    
    try:
        import akshare as ak
        df = ak.stock_hsgt_hist_em(symbol="å—å‘èµ„é‡‘")
        if df.empty:
            return None
        
        df = df.sort_values('æ—¥æœŸ', ascending=False)
        latest = df.iloc[0]
        last_5 = df.head(5)
        
        result = {
            'date': str(latest['æ—¥æœŸ']),
            'daily_net': round(float(latest['å½“æ—¥æˆäº¤å‡€ä¹°é¢']), 2),
            'sum_5d': round(float(last_5['å½“æ—¥æˆäº¤å‡€ä¹°é¢'].sum()), 2),
            'cumulative': round(float(latest['å†å²ç´¯è®¡å‡€ä¹°é¢']), 2),
        }
        _set_cached('southbound_flow', result)
        return result
    except Exception as e:
        log.warning(f"å—å‘èµ„é‡‘è·å–å¤±è´¥: {e}")
        return None


def fetch_report_disclosure(code: str) -> Optional[Dict]:
    """æŸ¥è¯¢ä¸‹ä¸€ä»½è´¢æŠ¥çš„é¢„è®¡æŠ«éœ²æ—¶é—´å’Œæ˜¯å¦å·²å‘å¸ƒ"""
    cache_key = f'report_disclosure_{code}'
    cached = _get_cached(cache_key, max_age_hours=24)
    if cached:
        return cached
    
    try:
        import akshare as ak
        now = datetime.now()
        
        # ç¡®å®šå½“å‰åº”è¯¥ç­‰å“ªä»½æŠ¥å‘Š
        # 1-4æœˆç­‰å¹´æŠ¥ï¼Œ4-8æœˆç­‰åŠå¹´æŠ¥(æˆ–Q1)ï¼Œ8-10æœˆç­‰Q3
        if now.month <= 4:
            period = f"{now.year - 1}å¹´æŠ¥"
            report_name = f"{now.year - 1}å¹´æŠ¥"
        elif now.month <= 8:
            period = f"{now.year}åŠå¹´æŠ¥"
            report_name = f"{now.year}åŠå¹´æŠ¥"
        else:
            period = f"{now.year}ä¸‰å­£æŠ¥"
            report_name = f"{now.year}Q3"
        
        # å…ˆè¯•å¹´æŠ¥ï¼Œå¦‚æœå¹´æŠ¥å·²å‡ºå°±æŸ¥ä¸‹ä¸€ä»½
        df = ak.stock_report_disclosure(market="æ²ªæ·±äº¬", period=period)
        match = df[df['è‚¡ç¥¨ä»£ç '].astype(str).str.contains(code)]
        
        if match.empty:
            return None
        
        row = match.iloc[0]
        scheduled = str(row['é¦–æ¬¡é¢„çº¦']) if row['é¦–æ¬¡é¢„çº¦'] is not None else None
        actual = str(row['å®é™…æŠ«éœ²']) if row['å®é™…æŠ«éœ²'] is not None and str(row['å®é™…æŠ«éœ²']) != 'NaT' else None
        
        result = {
            'report_type': report_name,
            'scheduled_date': scheduled,
            'actual_date': actual,
            'is_published': actual is not None and actual != 'None' and actual != 'NaT',
        }
        
        # å¦‚æœå·²å‘å¸ƒï¼ŒæŸ¥ä¸‹ä¸€ä»½
        if result['is_published']:
            # å¹´æŠ¥å‡ºäº†â†’ç­‰Q1ï¼ŒåŠå¹´æŠ¥å‡ºäº†â†’ç­‰Q3
            if 'å¹´æŠ¥' in period:
                next_period = f"{now.year}ä¸€å­£æŠ¥"
            elif 'åŠå¹´æŠ¥' in period:
                next_period = f"{now.year}ä¸‰å­£æŠ¥"
            else:
                next_period = f"{now.year}å¹´æŠ¥"
            
            try:
                df2 = ak.stock_report_disclosure(market="æ²ªæ·±äº¬", period=next_period)
                match2 = df2[df2['è‚¡ç¥¨ä»£ç '].astype(str).str.contains(code)]
                if not match2.empty:
                    row2 = match2.iloc[0]
                    result['next_report'] = next_period
                    result['next_scheduled'] = str(row2['é¦–æ¬¡é¢„çº¦']) if row2['é¦–æ¬¡é¢„çº¦'] is not None else None
            except:
                pass
        
        _set_cached(cache_key, result)
        return result
    except Exception as e:
        log.warning(f"è´¢æŠ¥æŠ«éœ²æŸ¥è¯¢å¤±è´¥ {code}: {e}")
        return None


def fetch_monthly_sales_data(code: str, company_name: str, months: int = 6) -> Optional[Dict]:
    """ä¸‹è½½å¹¶è§£ææœˆåº¦äº§é”€å¿«æŠ¥PDFï¼Œæå–é”€é‡æ•°æ®å’Œè¶‹åŠ¿åˆ†æ"""
    cache_key = f'monthly_sales_{code}'
    cached = _get_cached(cache_key, max_age_hours=24)
    if cached:
        return cached
    
    try:
        import pdfplumber
        import io
        import re
        
        # æœç´¢äº§é”€å¿«æŠ¥å…¬å‘Š
        url = "http://www.cninfo.com.cn/new/fulltextSearch/full"
        headers = {"User-Agent": "Mozilla/5.0"}
        params = {
            "searchkey": f"{company_name} äº§é”€å¿«æŠ¥",
            "sdate": (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d'),
            "edate": datetime.now().strftime('%Y-%m-%d'),
            "isfulltext": "false", "sortName": "pubdate", "sortType": "desc",
            "pageNum": "1", "pageSize": str(months + 2),
        }
        r = requests.get(url, headers=headers, params=params, timeout=10)
        anns = r.json().get("announcements") or []
        
        if not anns:
            return None
        
        monthly = []
        for ann in anns[:months]:
            title = re.sub(r'<[^>]+>', '', ann.get('announcementTitle', ''))
            month_match = re.search(r'(\d{4})å¹´(\d{1,2})æœˆ', title)
            if not month_match:
                continue
            
            year, month = int(month_match.group(1)), int(month_match.group(2))
            pdf_url = f"http://static.cninfo.com.cn/{ann.get('adjunctUrl', '')}"
            
            try:
                pdf_r = requests.get(pdf_url, headers={"User-Agent": "Mozilla/5.0"}, timeout=15)
                with pdfplumber.open(io.BytesIO(pdf_r.content)) as pdf:
                    tables = pdf.pages[0].extract_tables()
                    if tables:
                        for row in tables[0]:
                            if row and row[0] and 'åˆè®¡' in str(row[0]):
                                # å¤„ç†åƒåˆ†ä½é€—å·
                                def parse_int(s):
                                    if s is None: return 0
                                    return int(str(s).replace(',', '').strip())
                                
                                monthly.append({
                                    'period': f"{year}-{month:02d}",
                                    'year': year, 'month': month,
                                    'production': parse_int(row[1]),
                                    'prod_yoy': str(row[3] or ''),
                                    'sales': parse_int(row[7]),
                                    'sales_yoy': str(row[9] or ''),
                                })
                                break
            except Exception as e:
                log.debug(f"PDFè§£æå¤±è´¥ {year}-{month:02d}: {e}")
        
        if not monthly:
            return None
        
        monthly.sort(key=lambda x: (x['year'], x['month']))
        
        # === åˆ†æ ===
        latest = monthly[-1]
        analysis = {
            'monthly_data': monthly,
            'latest_period': latest['period'],
            'latest_sales': latest['sales'],
            'latest_sales_yoy': latest['sales_yoy'],
            'latest_production': latest['production'],
        }
        
        # ç¯æ¯”
        if len(monthly) >= 2:
            prev = monthly[-2]
            if prev['sales'] > 0:
                mom = (latest['sales'] - prev['sales']) / prev['sales'] * 100
                analysis['mom_change'] = round(mom, 1)
                analysis['prev_period'] = prev['period']
                analysis['prev_sales'] = prev['sales']
        
        # è¿‘3æœˆè¶‹åŠ¿
        if len(monthly) >= 3:
            recent3 = [d['sales'] for d in monthly[-3:]]
            if all(recent3[i] >= recent3[i-1] for i in range(1, len(recent3))):
                analysis['trend'] = 'è¿ç»­ä¸Šå‡'
            elif all(recent3[i] <= recent3[i-1] for i in range(1, len(recent3))):
                analysis['trend'] = 'è¿ç»­ä¸‹é™'
            else:
                analysis['trend'] = 'æ³¢åŠ¨'
        
        # æœˆé”€ä¸‡è¾†é‡Œç¨‹ç¢‘
        analysis['above_10k'] = latest['sales'] >= 10000
        if not analysis['above_10k']:
            analysis['gap_to_10k'] = 10000 - latest['sales']
        
        _set_cached(cache_key, analysis)
        return analysis
    except Exception as e:
        log.warning(f"äº§é”€æ•°æ®è·å–å¤±è´¥ {code}: {e}")
        return None


def fetch_announcement_search(code: str, keyword: str, company_name: str = "", limit: int = 3) -> Optional[List[Dict]]:
    """å·¨æ½®å…¬å‘Šå…¨æ–‡æœç´¢"""
    cache_key = f'ann_{code}_{keyword}'
    cached = _get_cached(cache_key, max_age_hours=12)
    if cached:
        return cached
    
    try:
        import re as _re
        search_term = f"{company_name} {keyword}" if company_name else keyword
        
        url = "http://www.cninfo.com.cn/new/fulltextSearch/full"
        headers = {"User-Agent": "Mozilla/5.0"}
        params = {
            "searchkey": search_term,
            "sdate": (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d'),
            "edate": datetime.now().strftime('%Y-%m-%d'),
            "isfulltext": "false",
            "sortName": "pubdate",
            "sortType": "desc",
            "pageNum": "1",
            "pageSize": str(limit),
        }
        r = requests.get(url, headers=headers, params=params, timeout=10)
        result = r.json()
        announcements = result.get("announcements") or []
        
        parsed = []
        for ann in announcements[:limit]:
            ts = ann.get('announcementTime', 0)
            date = datetime.fromtimestamp(ts / 1000).strftime('%Y-%m-%d') if ts else None
            title = _re.sub(r'<[^>]+>', '', ann.get('announcementTitle', ''))
            parsed.append({
                'title': title,
                'date': date,
            })
        
        _set_cached(cache_key, parsed)
        return parsed
    except Exception as e:
        log.warning(f"å…¬å‘Šæœç´¢å¤±è´¥ {code} {keyword}: {e}")
        return None


def fetch_commodity_prices(products: List[str], cost_driver: str = None) -> Dict[str, Optional[Dict]]:
    """è·å–å•†å“ç°è´§ä»·æ ¼
    
    ç­–ç•¥ï¼š
    1. æœ‰æœŸè´§çš„å“ç§ï¼ˆç‰ç±³ï¼‰â†’ akshareæœŸè´§è¡Œæƒ…
    2. æ— æœŸè´§çš„åŒ–å·¥å“ï¼ˆå‘³ç²¾/èµ–æ°¨é…¸/è‹æ°¨é…¸ï¼‰â†’ è¯»å–ç¼“å­˜æ–‡ä»¶ commodity_prices.json
       ç¼“å­˜ç”±å¤–éƒ¨å®šæ—¶æ›´æ–°ï¼ˆcron webæœç´¢ æˆ– æ‰‹åŠ¨ç»´æŠ¤ï¼‰
    """
    FUTURES_MAP = {
        'ç‰ç±³': 'C0',
        'è±†ç²•': 'M0',
        'æ£‰èŠ±': 'CF0',
    }
    
    COMMODITY_PRICES_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data", "commodity_prices.json")
    
    # åŠ è½½æ‰‹åŠ¨/åŠè‡ªåŠ¨ç»´æŠ¤çš„ä»·æ ¼ç¼“å­˜
    manual_prices = {}
    if os.path.exists(COMMODITY_PRICES_FILE):
        try:
            with open(COMMODITY_PRICES_FILE, 'r', encoding='utf-8') as f:
                manual_prices = json.load(f)
        except:
            pass
    
    all_products = list(products) + ([cost_driver] if cost_driver and cost_driver not in products else [])
    results = {}
    
    for product in all_products:
        cache_key = f'commodity_{product}'
        cached = _get_cached(cache_key, max_age_hours=12)
        if cached:
            results[product] = cached
            continue
        
        # 1. æœŸè´§å“ç§
        if product in FUTURES_MAP:
            try:
                import akshare as ak
                df = ak.futures_zh_daily_sina(symbol=FUTURES_MAP[product])
                if not df.empty:
                    df = df.sort_values('date', ascending=False)
                    latest = df.iloc[0]
                    prev_30 = df.iloc[min(22, len(df)-1)] if len(df) > 22 else df.iloc[-1]
                    price = float(latest['close'])
                    prev_price = float(prev_30['close'])
                    change_30d = (price - prev_price) / prev_price * 100 if prev_price > 0 else 0
                    
                    data = {
                        'price': price,
                        'unit': 'å…ƒ/å¨',
                        'change_30d': round(change_30d, 1),
                        'date': str(latest['date']),
                        'source': 'æœŸè´§ä¸»åŠ›',
                    }
                    _set_cached(cache_key, data)
                    results[product] = data
                    continue
            except Exception as e:
                log.debug(f"æœŸè´§è¡Œæƒ…è·å–å¤±è´¥ {product}: {e}")
        
        # 2. æ‰‹åŠ¨ç¼“å­˜æ–‡ä»¶
        if product in manual_prices:
            mp = manual_prices[product]
            # æ£€æŸ¥æ˜¯å¦å¤ªæ—§ï¼ˆè¶…è¿‡7å¤©å‘Šè­¦ï¼‰
            date_str = mp.get('date', '')
            age_days = None
            if date_str:
                try:
                    age_days = (datetime.now() - datetime.strptime(date_str, '%Y-%m-%d')).days
                except:
                    pass
            
            data = {
                'price': mp.get('price', 0),
                'unit': mp.get('unit', 'å…ƒ/å¨'),
                'change_30d': mp.get('change_30d', 0),
                'date': date_str,
                'source': mp.get('source', 'è¡Œä¸šæŠ¥ä»·'),
                'stale': age_days is not None and age_days > 7,
            }
            results[product] = data
            continue
        
        results[product] = None
    
    return results


# ============================================================
# æŒ‡æ ‡å¼•æ“
# ============================================================

class IndicatorEngine:
    """åŠ¨æ€æ ¸å¿ƒæŒ‡æ ‡å¼•æ“"""
    
    def generate_indicators(self, holding: Dict, fundamentals: Dict = None) -> List[Dict]:
        """
        æ ¹æ®æŒä»“çš„ stock_class + è¡Œä¸š + å½“å‰çŠ¶æ€ï¼Œè‡ªåŠ¨ç”ŸæˆæŒ‡æ ‡
        
        è¿”å›: [{name, icon, text, status}]
        """
        stock_class = holding.get('stock_class', '')
        h_type = holding.get('type', 'stock')
        code = holding.get('code', '')
        notes = holding.get('notes', '')
        
        indicators = []
        
        # ä»£æŒ/è·Ÿéš â†’ ä¸è·Ÿè¸ª
        if 'æ“ç›˜æ‰‹' in notes or 'ä»£æŒ' in notes or 'è·Ÿéš' in notes:
            indicators.append({
                'name': 'è·Ÿéš',
                'icon': 'ğŸ‘¤',
                'text': 'è·Ÿéšæ“ç›˜æ‰‹æŒ‡ä»¤ï¼Œä¸åšç‹¬ç«‹è·Ÿè¸ª',
                'status': 'info',
            })
            return indicators
        
        # ETF â†’ èµ„é‡‘æµå‘
        if h_type == 'etf':
            indicators.extend(self._etf_indicators(holding))
            return indicators
        
        # æŒ‰æ—å¥‡åˆ†ç±»åˆ†å‘
        if stock_class == 'æˆé•¿è‚¡':
            indicators.extend(self._growth_indicators(holding, fundamentals))
        elif stock_class == 'å‘¨æœŸè‚¡':
            indicators.extend(self._cyclical_indicators(holding, fundamentals))
        elif stock_class == 'ä»·å€¼è‚¡':
            indicators.extend(self._value_indicators(holding, fundamentals))
        elif stock_class == 'å›°å¢ƒåè½¬':
            indicators.extend(self._turnaround_indicators(holding, fundamentals))
        else:
            # é€šç”¨ï¼šè´¢æŠ¥ç›‘æ§
            indicators.extend(self._common_indicators(holding, fundamentals))
        
        return indicators
    
    def _etf_indicators(self, holding: Dict) -> List[Dict]:
        """ETFæŒ‡æ ‡ï¼šèµ„é‡‘æµå‘"""
        indicators = []
        code = holding.get('code', '')
        name = holding.get('name', '')
        
        # æ’ç”Ÿç§‘æŠ€ â†’ å—å‘èµ„é‡‘
        if 'æ’ç”Ÿ' in name or 'æ¸¯è‚¡' in name:
            flow = fetch_southbound_flow()
            if flow:
                daily = flow['daily_net']
                sum5 = flow['sum_5d']
                daily_icon = 'ğŸ“ˆ' if daily > 0 else 'ğŸ“‰'
                indicators.append({
                    'name': 'å—å‘èµ„é‡‘',
                    'icon': 'ğŸ’°',
                    'text': f"æœ€æ–°{daily_icon}{daily:+.1f}äº¿ | è¿‘5æ—¥{sum5:+.1f}äº¿",
                    'status': 'good' if daily > 0 else 'warn',
                })
            else:
                indicators.append({
                    'name': 'å—å‘èµ„é‡‘',
                    'icon': 'ğŸ’°',
                    'text': 'æ•°æ®è·å–ä¸­...',
                    'status': 'loading',
                })
        
        return indicators
    
    def _growth_indicators(self, holding: Dict, fundamentals: Dict) -> List[Dict]:
        """æˆé•¿è‚¡ï¼šè´¢æŠ¥æŠ«éœ² + å¢é€Ÿè¶‹åŠ¿"""
        indicators = []
        code = holding.get('code', '')
        
        # ä¸‹ä¸€ä»½è´¢æŠ¥
        report = fetch_report_disclosure(code)
        if report:
            if report['is_published']:
                next_info = report.get('next_report', '')
                next_date = report.get('next_scheduled', '')
                indicators.append({
                    'name': 'è´¢æŠ¥',
                    'icon': 'ğŸ“…',
                    'text': f"{report['report_type']}å·²å‘å¸ƒ | ä¸‹ä¸€ä»½: {next_info} é¢„è®¡{next_date}",
                    'status': 'info',
                })
            else:
                scheduled = report['scheduled_date']
                days_left = None
                if scheduled and scheduled != 'None':
                    try:
                        target = datetime.strptime(scheduled[:10], '%Y-%m-%d')
                        days_left = (target - datetime.now()).days
                    except:
                        pass
                
                urgency = ''
                if days_left is not None:
                    if days_left <= 7:
                        urgency = f' âš ï¸ä»…å‰©{days_left}å¤©'
                    elif days_left <= 30:
                        urgency = f' ({days_left}å¤©å)'
                
                indicators.append({
                    'name': 'è´¢æŠ¥',
                    'icon': 'ğŸ“…',
                    'text': f"{report['report_type']}æœªå‘å¸ƒ é¢„è®¡{scheduled}{urgency}",
                    'status': 'wait',
                })
        
        return indicators
    
    def _cyclical_indicators(self, holding: Dict, fundamentals: Dict) -> List[Dict]:
        """å‘¨æœŸè‚¡ï¼šäº§å“ä»·æ ¼ + è´¢æŠ¥"""
        indicators = []
        code = holding.get('code', '')
        hints = holding.get('indicator_hints', {})
        
        # äº§å“ä»·æ ¼
        products = hints.get('products', [])
        cost_driver = hints.get('cost_driver')
        
        if products:
            prices = fetch_commodity_prices(products, cost_driver=cost_driver)
            
            price_parts = []
            for p in products:
                data = prices.get(p)
                if data:
                    chg = data.get('change_30d', 0)
                    icon = 'ğŸ“ˆ' if chg > 0 else 'ğŸ“‰' if chg < 0 else 'â¡ï¸'
                    stale = 'âš ï¸' if data.get('stale') else ''
                    price_parts.append(f"{p}{icon}{data['price']}{data['unit']}(æœˆ{chg:+.1f}%){stale}")
                else:
                    price_parts.append(f"{p}: æš‚æ— æ•°æ®")
            
            if cost_driver:
                cost_data = prices.get(cost_driver)
                if cost_data:
                    chg = cost_data.get('change_30d', 0)
                    icon = 'ğŸ“ˆ' if chg > 0 else 'ğŸ“‰'
                    price_parts.append(f"æˆæœ¬({cost_driver}){icon}{cost_data['price']}(æœˆ{chg:+.1f}%)")
            
            indicators.append({
                'name': 'äº§å“ä»·æ ¼',
                'icon': 'ğŸ“Š',
                'text': ' | '.join(price_parts),
                'status': 'info',
            })
        
        # è´¢æŠ¥
        indicators.extend(self._growth_indicators(holding, fundamentals))
        
        return indicators
    
    def _value_indicators(self, holding: Dict, fundamentals: Dict) -> List[Dict]:
        """ä»·å€¼è‚¡ï¼šè‚¡æ¯ç‡/åˆ†çº¢ + è´¢æŠ¥"""
        indicators = []
        code = holding.get('code', '')
        name = holding.get('name', '')
        
        # é“¶è¡Œè‚¡ç‰¹æœ‰ï¼šå‡€æ¯å·®
        industry = ''
        if fundamentals:
            industry = fundamentals.get('industry', '') or ''
        if any(kw in name or kw in industry for kw in ['é“¶è¡Œ', 'å†œå•†', 'é‡‘è']):
            indicators.append({
                'name': 'å…³æ³¨',
                'icon': 'ğŸ¦',
                'text': 'æ ¸å¿ƒçœ‹å‡€æ¯å·®+åˆ†çº¢æ–¹æ¡ˆï¼ˆå¾…å¹´æŠ¥æŠ«éœ²ï¼‰',
                'status': 'info',
            })
        
        # è´¢æŠ¥æŠ«éœ²
        indicators.extend(self._growth_indicators(holding, fundamentals))
        
        return indicators
    
    def _turnaround_indicators(self, holding: Dict, fundamentals: Dict) -> List[Dict]:
        """å›°å¢ƒåè½¬è‚¡ï¼šæœˆåº¦äº§é”€æ•°æ®åˆ†æ + æ¯›åˆ©ç‡"""
        indicators = []
        code = holding.get('code', '')
        name = holding.get('name', '')
        hints = holding.get('indicator_hints', {})
        
        # æœˆåº¦äº§é”€æ•°æ®ï¼ˆä¸‹è½½PDFæå–+åˆ†æï¼‰
        sales_data = fetch_monthly_sales_data(code, name, months=6)
        if sales_data:
            latest_sales = sales_data['latest_sales']
            yoy = sales_data['latest_sales_yoy']
            period = sales_data['latest_period']
            
            # é”€é‡æ¦‚å†µ
            parts = [f"{period} é”€é‡{latest_sales:,}è¾† åŒæ¯”{yoy}"]
            
            # ç¯æ¯”
            mom = sales_data.get('mom_change')
            if mom is not None:
                mom_icon = 'ğŸ“ˆ' if mom > 0 else 'ğŸ“‰'
                parts.append(f"ç¯æ¯”{mom_icon}{mom:+.1f}%")
            
            indicators.append({
                'name': 'äº§é”€',
                'icon': 'ğŸš—',
                'text': ' | '.join(parts),
                'status': 'good' if latest_sales >= 10000 else 'info',
            })
            
            # è¿‘å‡ æœˆè¶‹åŠ¿
            monthly = sales_data.get('monthly_data', [])
            if len(monthly) >= 3:
                trend_parts = [f"{d['period'][-2:]}æœˆ:{d['sales']:,}" for d in monthly[-4:]]
                trend = sales_data.get('trend', '')
                trend_icon = 'ğŸ“ˆ' if trend == 'è¿ç»­ä¸Šå‡' else 'ğŸ“‰' if trend == 'è¿ç»­ä¸‹é™' else 'â†”ï¸'
                indicators.append({
                    'name': 'è¶‹åŠ¿',
                    'icon': trend_icon,
                    'text': f"{'â†’'.join(trend_parts)} ({trend})",
                    'status': 'good' if trend == 'è¿ç»­ä¸Šå‡' else 'warn' if trend == 'è¿ç»­ä¸‹é™' else 'info',
                })
            
            # æ™ºèƒ½ç‚¹è¯„
            comment = self._analyze_sales_context(sales_data)
            if comment:
                indicators.append({
                    'name': 'ç‚¹è¯„',
                    'icon': 'ğŸ’¬',
                    'text': comment,
                    'status': 'analysis',
                })
            
            # å…³é”®é‡Œç¨‹ç¢‘åˆ¤æ–­
            if sales_data.get('above_10k'):
                indicators.append({
                    'name': 'é‡Œç¨‹ç¢‘',
                    'icon': 'ğŸ¯',
                    'text': 'æœˆé”€ç ´ä¸‡âœ… â†’ åŠ ä»“ä¿¡å·ï¼',
                    'status': 'milestone',
                })
            else:
                gap = sales_data.get('gap_to_10k', 0)
                indicators.append({
                    'name': 'é‡Œç¨‹ç¢‘',
                    'icon': 'ğŸ¯',
                    'text': f'è·æœˆé”€ä¸‡è¾†è¿˜å·®{gap:,}è¾†',
                    'status': 'wait',
                })
            
            # ä¸‹æœŸé¢„è®¡
            if monthly:
                last_month = monthly[-1]['month']
                last_year = monthly[-1]['year']
                next_month = last_month + 1
                next_year = last_year
                if next_month > 12:
                    next_month = 1
                    next_year += 1
                indicators.append({
                    'name': 'ä¸‹æœŸ',
                    'icon': 'â³',
                    'text': f'{next_year}å¹´{next_month}æœˆäº§é”€å¿«æŠ¥é¢„è®¡{next_month+1}æœˆåˆå‘å¸ƒ',
                    'status': 'wait',
                })
        else:
            # fallback: å…¬å‘Šæœç´¢
            ops_keyword = hints.get('ops_keyword', 'äº§é”€')
            anns = fetch_announcement_search(code, ops_keyword, company_name=name, limit=3)
            if anns:
                indicators.append({
                    'name': 'ç»è¥æ•°æ®',
                    'icon': 'ğŸ“‹',
                    'text': f"æœ€æ–°: [{anns[0]['date']}] {anns[0]['title'][:30]}",
                    'status': 'info',
                })
            else:
                indicators.append({
                    'name': 'ç»è¥æ•°æ®',
                    'icon': 'ğŸ“‹',
                    'text': 'æœªæ‰¾åˆ°äº§é”€æ•°æ®',
                    'status': 'warn',
                })
        
        # è´¢æŠ¥
        indicators.extend(self._growth_indicators(holding, fundamentals))
        
        return indicators
    
    def _analyze_sales_context(self, sales_data: Dict) -> Optional[str]:
        """æ ¹æ®äº§é”€æ•°æ®ç»™å‡ºæ™ºèƒ½ç‚¹è¯„"""
        latest_sales = sales_data.get('latest_sales', 0)
        mom = sales_data.get('mom_change')
        yoy_str = sales_data.get('latest_sales_yoy', '')
        period = sales_data.get('latest_period', '')
        monthly = sales_data.get('monthly_data', [])
        
        # è§£æåŒæ¯”æ•°å€¼
        yoy = None
        try:
            yoy = float(yoy_str.replace('%', '').replace('+', ''))
        except:
            pass
        
        comments = []
        
        # æ˜¥èŠ‚æœˆåˆ¤æ–­ï¼ˆ1-2æœˆï¼‰
        month = int(period.split('-')[1]) if '-' in period else 0
        if month in [1, 2] and mom is not None and mom < -30:
            comments.append(f"æ˜¥èŠ‚æœˆç¯æ¯”å¤§è·Œå±å­£èŠ‚æ€§æ­£å¸¸")
            # è·Ÿå»å¹´åŒæœŸæ¯”æ›´æœ‰æ„ä¹‰
            if yoy is not None:
                if yoy > 20:
                    comments.append(f"åŒæ¯”+{yoy:.0f}%è¡¨ç°å¼ºåŠ²")
                elif yoy > 0:
                    comments.append(f"åŒæ¯”ä»æ­£å¢é•¿ï¼ŒåŸºæœ¬é¢æœªæ¶åŒ–")
                else:
                    comments.append(f"âš ï¸åŒæ¯”è½¬è´Ÿéœ€è­¦æƒ•")
        else:
            # éæ˜¥èŠ‚æœˆ
            if mom is not None:
                if mom > 20:
                    comments.append("ç¯æ¯”å¤§å¢ï¼Œæ”¾é‡ä¿¡å·")
                elif mom < -20:
                    comments.append("âš ï¸ç¯æ¯”å¤§è·Œï¼Œå…³æ³¨æ˜¯å¦è¶‹åŠ¿æ€§ä¸‹æ»‘")
            
            if yoy is not None:
                if yoy > 50:
                    comments.append("åŒæ¯”é«˜å¢é•¿ï¼Œåè½¬åŠ é€Ÿ")
                elif yoy > 0:
                    comments.append("åŒæ¯”æ­£å¢é•¿")
                else:
                    comments.append("âš ï¸åŒæ¯”ä¸‹æ»‘")
        
        # è¿ç»­è¶‹åŠ¿åˆ¤æ–­
        if len(monthly) >= 4:
            # æ’é™¤æœ€æ–°æœˆ(å¯èƒ½æ˜¥èŠ‚)ï¼Œçœ‹ä¹‹å‰3ä¸ªæœˆè¶‹åŠ¿
            prev3 = [d['sales'] for d in monthly[-4:-1]]
            if all(prev3[i] > prev3[i-1] for i in range(1, len(prev3))):
                comments.append("å‰3æœˆé”€é‡æŒç»­æ”€å‡")
        
        return 'ï¼›'.join(comments) if comments else None
    
    def _common_indicators(self, holding: Dict, fundamentals: Dict) -> List[Dict]:
        """é€šç”¨æŒ‡æ ‡"""
        return self._growth_indicators(holding, fundamentals)


# ============================================================
# æ ¼å¼åŒ–
# ============================================================

def format_indicators(indicators: List[Dict]) -> List[str]:
    """å°†æŒ‡æ ‡åˆ—è¡¨æ ¼å¼åŒ–ä¸ºæŠ¥å‘Šè¡Œ"""
    if not indicators:
        return []
    
    lines = []
    for ind in indicators:
        icon = ind.get('icon', 'ğŸ”')
        text = ind.get('text', '')
        lines.append(f"   {icon} {text}")
    
    return lines


# ============================================================
# æµ‹è¯•
# ============================================================

if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
    
    # åŠ è½½ portfolio.json æµ‹è¯•
    import json
    with open(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'portfolio.json'), 'r') as f:  # portfolio.json stays in root
        portfolio = json.load(f)
    
    engine = IndicatorEngine()
    
    for h in portfolio['accounts'][0]['holdings']:
        print(f"\n=== {h['name']} ({h['code']}) [{h.get('stock_class', h.get('type'))}] ===")
        indicators = engine.generate_indicators(h)
        for line in format_indicators(indicators):
            print(line)
